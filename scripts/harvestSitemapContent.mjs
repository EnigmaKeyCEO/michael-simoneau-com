import { writeFile } from 'node:fs/promises';
import { resolve } from 'node:path';
import { execFile } from 'node:child_process';
import { promisify } from 'node:util';

const execFileAsync = promisify(execFile);

const ROOT_SITEMAP = 'https://michaelsimoneau.com/sitemap.xml';
const RENDER_PREFIX = 'https://r.jina.ai/';

const manualFragmentMap = {
  'https://michaelsimoneau.com/': {
    'about-me-section': 'my-journey-from-code-to-architect',
    'expertise-section': 'proven-expertise-impact',
    'service-offerings-section': 'expertise-service-offerings-driving-innovation-resilience',
    'crypto-fabric-section': 'new-launch',
    'cto-triage-section': 'strategic-technology-consulting',
    'blog-teaser-section': 'strategic-insights-perspectives',
  },
};

const slugify = (value) =>
  value
    .toLowerCase()
    .normalize('NFKD')
    .replace(/[\u0300-\u036f]/g, '')
    .replace(/[^a-z0-9]+/g, '-')
    .replace(/(^-|-$)/g, '');

const httpGet = async (url) => {
  const { stdout } = await execFileAsync('curl', ['-fsSL', url]);
  return stdout.toString();
};

const parseSitemap = async (sitemapUrl) => {
  const xml = await httpGet(sitemapUrl);
  const matches = [...xml.matchAll(/<loc>(.*?)<\/loc>/g)];
  return matches.map((match) => match[1]);
};

const fetchMarkdown = async (url) => {
  const text = await httpGet(`${RENDER_PREFIX}${url}`);
  const lines = text.split(/\r?\n/);
  const titleLine = lines.find((line) => line.startsWith('Title:')) ?? '';
  const title = titleLine.replace('Title:', '').trim();
  const markerIndex = lines.findIndex((line) => line.trim() === 'Markdown Content:');
  const contentLines = markerIndex >= 0 ? lines.slice(markerIndex + 1) : lines;
  const content = contentLines.join('\n').trim();
  return { title, content };
};

const extractSections = (markdown) => {
  const lines = markdown.split(/\r?\n/);
  const sections = [];
  let index = 0;
  while (index < lines.length) {
    const line = lines[index];
    if (line.startsWith('#')) {
      const level = line.match(/^#+/)[0].length;
      const title = line.slice(level).trim();
      const slug = slugify(title);
      let contentStart = index + 1;
      let contentEnd = contentStart;
      while (contentEnd < lines.length) {
        const nextLine = lines[contentEnd];
        if (nextLine.startsWith('#') || /^[-=]{3,}$/.test(lines[contentEnd + 1] ?? '')) {
          break;
        }
        contentEnd += 1;
      }
      sections.push({ slug, title, start: index, end: contentEnd });
      index = contentEnd;
      continue;
    }

    const nextLine = lines[index + 1];
    if (nextLine && /^[-=]{3,}$/.test(nextLine.trim()) && line.trim()) {
      const title = line.trim();
      const slug = slugify(title);
      let contentStart = index + 2;
      let contentEnd = contentStart;
      while (contentEnd < lines.length) {
        const candidate = lines[contentEnd];
        const candidateNext = lines[contentEnd + 1];
        if (candidate.startsWith('#') || (candidateNext && /^[-=]{3,}$/.test(candidateNext))) {
          break;
        }
        if (candidate.startsWith('Title:')) {
          break;
        }
        contentEnd += 1;
      }
      sections.push({ slug, title, start: index, end: contentEnd });
      index = contentEnd;
      continue;
    }

    index += 1;
  }

  const sectionContent = {};
  sections.forEach((section) => {
    const slice = lines.slice(section.start, section.end).join('\n').trim();
    if (slice) {
      sectionContent[section.slug] = slice;
    }
  });

  return sectionContent;
};

const main = async () => {
  const sitemapUrls = await parseSitemap(ROOT_SITEMAP);
  const nested = await Promise.all(sitemapUrls.map(parseSitemap));
  const urls = [...new Set(nested.flat())];

  const baseCache = new Map();
  const records = [];

  for (const rawUrl of urls) {
    const url = new URL(rawUrl);
    const fragment = url.hash ? url.hash.slice(1) : null;
    url.hash = '';
    const baseUrl = url.toString();

    if (!baseCache.has(baseUrl)) {
      const data = await fetchMarkdown(baseUrl);
      baseCache.set(baseUrl, {
        ...data,
        sections: extractSections(data.content),
      });
    }

    const baseData = baseCache.get(baseUrl);
    const fragmentMap = manualFragmentMap[baseUrl] ?? {};
    const preferredSlug = fragment ? (fragmentMap[fragment] ?? fragment) : null;
    const sectionContent = preferredSlug ? baseData.sections[preferredSlug] : null;

    records.push({
      url: rawUrl,
      baseUrl,
      fragment,
      title: baseData.title,
      content: sectionContent ?? baseData.content,
    });
  }

  records.sort((a, b) => a.url.localeCompare(b.url));
  const outputPath = resolve('src/features/home/data/sitemapContent.ts');
  const fileContent = `// Auto-generated by scripts/harvestSitemapContent.mjs\n\nexport type ScrapedContent = {\n  url: string;\n  baseUrl: string;\n  fragment: string | null;\n  title: string;\n  content: string;\n};\n\nexport const SCRAPED_CONTENT: ScrapedContent[] = ${JSON.stringify(records, null, 2)};\n`;

  await writeFile(outputPath, fileContent, 'utf8');
  console.log(`Wrote ${records.length} records to ${outputPath}`);
};

main().catch((error) => {
  console.error(error);
  process.exit(1);
});
